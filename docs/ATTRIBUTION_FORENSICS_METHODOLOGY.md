# Attribution Forensics Methodology
## A Scalable Framework for Marketplace Attribution Detection and Remediation

**Version**: 1.0
**Author**: Claude Code Attribution Forensics Working Group
**Date**: November 5, 2025

---

## Executive Summary

Large software marketplaces (npm, VS Code, Claude Code, GitHub Actions, etc.) frequently contain derivative works without proper attribution. This document proposes a comprehensive, scalable methodology for:

1. **Detection** - Identifying potential derivative works across marketplaces
2. **Verification** - Documenting evidence of attribution gaps
3. **Remediation** - Automated attribution and compliance workflows
4. **Prevention** - Continuous monitoring and enforcement

This methodology can be implemented as a **Claude Code Plugin** with supporting tools and automation.

---

## Table of Contents

1. [Problem Statement](#problem-statement)
2. [Methodology Overview](#methodology-overview)
3. [Detection Techniques](#detection-techniques)
4. [Evidence Collection](#evidence-collection)
5. [Remediation Strategies](#remediation-strategies)
6. [Implementation Architecture](#implementation-architecture)
7. [Claude Code Plugin Design](#claude-code-plugin-design)
8. [Scalability Considerations](#scalability-considerations)
9. [Legal and Ethical Framework](#legal-and-ethical-framework)

---

## Problem Statement

### The Attribution Crisis

**Scale of the Problem:**
- npm: ~2.5M packages (many derivatives)
- VS Code Marketplace: ~50K extensions
- GitHub Actions: ~20K actions
- Claude Code components: Growing marketplace
- Docker Hub: ~10M+ container images

**Common Issues:**
- ğŸš« Missing license files
- ğŸš« No attribution to original authors
- ğŸš« License violations (GPL derivatives as MIT)
- ğŸš« Code copying without acknowledgment
- ğŸš« "Inspired by" without proper citation

**Impact:**
- Legal liability for marketplace operators
- Community trust erosion
- Original authors not credited
- Open source license violations
- Difficulty tracking provenance

### Why Existing Solutions Fail

1. **Manual Review**: Doesn't scale to millions of packages
2. **Simple License Scanners**: Only check declared licenses, not actual content
3. **GitHub's Dependency Graph**: Doesn't track code-level copying
4. **Marketplace Policies**: Reactive, not proactive
5. **DMCA Takedowns**: Nuclear option, doesn't fix attribution

---

## Methodology Overview

### The 5-Phase Attribution Forensics Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ATTRIBUTION FORENSICS                     â”‚
â”‚                      PIPELINE v1.0                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 1: DISCOVERY
â”œâ”€â”€ Crawl marketplace catalog
â”œâ”€â”€ Extract metadata (names, descriptions, keywords)
â”œâ”€â”€ Build resource graph
â””â”€â”€ Identify suspicious patterns

Phase 2: FINGERPRINTING
â”œâ”€â”€ Content hashing (file-level, function-level)
â”œâ”€â”€ Semantic embeddings (code understanding)
â”œâ”€â”€ License signature extraction
â””â”€â”€ Author attribution patterns

Phase 3: MATCHING
â”œâ”€â”€ Cross-repository similarity search
â”œâ”€â”€ Historical source detection
â”œâ”€â”€ Temporal analysis (who published first?)
â””â”€â”€ Network effects (copying clusters)

Phase 4: VERIFICATION
â”œâ”€â”€ Manual review queue (high-confidence matches)
â”œâ”€â”€ Evidence collection and documentation
â”œâ”€â”€ Confidence scoring
â””â”€â”€ False positive filtering

Phase 5: REMEDIATION
â”œâ”€â”€ Attribution header generation
â”œâ”€â”€ License compliance reports
â”œâ”€â”€ Automated PR creation
â”œâ”€â”€ Marketplace metadata updates
â””â”€â”€ Continuous monitoring
```

---

## Detection Techniques

### 1. Content-Based Detection

#### A. Code Similarity Analysis

**Technique**: Multi-level similarity matching

```python
# Pseudocode for similarity detection
class ContentFingerprinter:
    def fingerprint(self, resource):
        return {
            'exact_hash': sha256(normalize(resource.content)),
            'fuzzy_hash': ssdeep(resource.content),
            'ast_hash': hash_ast_structure(resource.code),
            'semantic_embedding': embed_code_semantics(resource.code),
            'token_ngrams': extract_ngrams(tokenize(resource.code), n=5)
        }

    def similarity(self, fingerprint1, fingerprint2):
        return {
            'exact_match': fingerprint1.exact_hash == fingerprint2.exact_hash,
            'fuzzy_score': ssdeep_compare(fingerprint1.fuzzy_hash, fingerprint2.fuzzy_hash),
            'ast_similarity': compare_ast(fingerprint1.ast_hash, fingerprint2.ast_hash),
            'semantic_similarity': cosine_similarity(
                fingerprint1.semantic_embedding,
                fingerprint2.semantic_embedding
            ),
            'token_overlap': jaccard(fingerprint1.token_ngrams, fingerprint2.token_ngrams)
        }
```

**Thresholds for Classification:**
- **Exact Copy** (100% match): Clear derivative
- **Near Copy** (90-99% match): Strong evidence of copying
- **Significant Similarity** (70-89% match): Likely derivative with modifications
- **Moderate Similarity** (50-69% match): Requires manual review
- **Inspired By** (30-49% match): May be reimplementation
- **Original** (<30% match): Not derivative

#### B. Metadata Analysis

**Signals of Potential Attribution Issues:**

1. **Temporal Signals**
   - Published date < original source date âŒ
   - Last commit timestamp analysis
   - Git history depth (shallow clone = suspicious)

2. **Author Signals**
   - Author mismatch between package and repository
   - Different maintainers than original
   - Multiple accounts from same entity

3. **Linguistic Signals**
   - Description similarity
   - README copying
   - Documentation structure matches

4. **Dependency Signals**
   - Same dependencies as original
   - Dependency version patterns
   - Import statement analysis

#### C. License Fingerprinting

**Technique**: Detect license violations and misattributions

```python
class LicenseForensics:
    def analyze_license_compliance(self, resource, potential_source):
        """
        Detect license violations in derivatives
        """
        return {
            'declared_license': resource.license,
            'detected_license_in_code': scan_license_headers(resource.code),
            'source_license': potential_source.license,
            'compliance_status': check_license_compatibility(
                resource.license,
                potential_source.license
            ),
            'attribution_present': has_attribution(resource, potential_source),
            'license_text_included': has_license_file(resource),
            'copyright_notices': extract_copyright_notices(resource)
        }
```

**License Violation Patterns:**
```
Source: GPL-3.0 â†’ Derivative: MIT         âŒ VIOLATION (GPL requires GPL)
Source: MIT     â†’ Derivative: Proprietary âš ï¸  ATTRIBUTION REQUIRED
Source: Apache  â†’ Derivative: MIT         âš ï¸  PATENT CLAUSE ISSUE
Source: MIT     â†’ Derivative: MIT         âœ… IF ATTRIBUTION PRESENT
```

### 2. Network-Based Detection

#### A. Marketplace Graph Analysis

**Build Resource Relationship Graph:**

```
Resource Graph Nodes:
- Packages/Components
- Authors/Organizations
- Licenses
- Source repositories
- Marketplace listings

Resource Graph Edges:
- depends_on (explicit)
- similar_to (computed)
- derived_from (detected)
- authored_by
- forks_from
- copied_from (temporal + similarity)
```

**Detection Algorithms:**

1. **Copying Cluster Detection**
   - Find groups of similar resources
   - Identify temporal "source" node
   - Trace copying patterns

2. **Author Network Analysis**
   - Detect "serial copiers"
   - Identify legitimate maintainers
   - Find coordinated copying operations

3. **License Propagation Analysis**
   - Track how licenses should propagate
   - Detect license violations in chains
   - Identify attribution breaking points

#### B. Community Intelligence

**Leverage Community Curated Lists:**

```python
class CommunityIntelligence:
    """
    Use curated lists like awesome-* to bootstrap detection
    """
    def __init__(self):
        self.curated_sources = [
            'awesome-claude-code',
            'awesome-vscode',
            'awesome-github-actions',
            # ... hundreds of awesome lists
        ]

    def bootstrap_detection(self):
        """
        Use curated lists as ground truth for attribution
        """
        for curated_list in self.curated_sources:
            resources = fetch_resources(curated_list)
            for resource in resources:
                # Mark as "known good source"
                self.index_source(resource)
                # Find potential derivatives in marketplace
                derivatives = self.find_marketplace_matches(resource)
                for derivative in derivatives:
                    self.verify_attribution(derivative, resource)
```

### 3. Temporal Analysis

**Publication Date Forensics:**

```python
def temporal_forensics(resource, potential_source):
    """
    Use timestamps to determine copying direction
    """
    timeline = {
        'source_first_commit': get_first_commit_date(potential_source.repo),
        'source_published': potential_source.published_date,
        'derivative_first_commit': get_first_commit_date(resource.repo),
        'derivative_published': resource.published_date,
        'similarity_score': calculate_similarity(resource, potential_source)
    }

    # Evidence scoring
    if timeline['derivative_first_commit'] > timeline['source_first_commit']:
        if timeline['similarity_score'] > 0.7:
            return {
                'verdict': 'LIKELY_DERIVATIVE',
                'confidence': 0.9,
                'evidence': 'Source published earlier + high similarity'
            }
```

---

## Evidence Collection

### Evidence Package Structure

For each potential attribution issue, collect comprehensive evidence:

```json
{
  "derivative_resource": {
    "marketplace": "npm",
    "name": "@example/package",
    "version": "1.0.0",
    "published_date": "2024-10-15",
    "author": "user123",
    "license": "MIT",
    "repository": "https://github.com/user123/package",
    "description": "A helpful utility package"
  },
  "suspected_source": {
    "marketplace": "github",
    "name": "original/package",
    "published_date": "2023-05-20",
    "author": "original-author",
    "license": "Apache-2.0",
    "repository": "https://github.com/original/package"
  },
  "similarity_evidence": {
    "content_similarity": 0.95,
    "ast_similarity": 0.89,
    "semantic_similarity": 0.92,
    "exact_matches": [
      "src/core/algorithm.js: 100% match",
      "src/utils/helpers.js: 98% match"
    ],
    "modified_sections": [
      "README.md: 45% different",
      "package.json: metadata changed"
    ]
  },
  "temporal_evidence": {
    "source_first_commit": "2023-05-18T10:30:00Z",
    "derivative_first_commit": "2024-10-10T15:20:00Z",
    "time_delta_days": 510,
    "verdict": "Source published 510 days earlier"
  },
  "license_analysis": {
    "source_license": "Apache-2.0",
    "derivative_license": "MIT",
    "compatibility": "INCOMPATIBLE",
    "violation_type": "Cannot relicense Apache-2.0 to MIT without permission",
    "attribution_present": false,
    "license_file_present": false
  },
  "metadata_evidence": {
    "description_similarity": 0.78,
    "keywords_overlap": 0.85,
    "dependency_overlap": 0.92,
    "readme_similarity": 0.65
  },
  "confidence_score": 0.94,
  "classification": "HIGH_CONFIDENCE_DERIVATIVE",
  "recommended_action": "REQUIRE_ATTRIBUTION_AND_LICENSE_CORRECTION"
}
```

### Evidence Visualization

Generate human-readable reports:

```markdown
# Attribution Evidence Report
## @example/package â†’ original/package

### ğŸ”´ HIGH CONFIDENCE DERIVATIVE (94%)

#### Evidence Summary:
- âœ… Source published 510 days earlier (2023-05-20)
- âœ… Content similarity: 95%
- âœ… AST similarity: 89%
- âœ… Exact file matches: 2 files (100% + 98%)
- âŒ No attribution to original author
- âŒ License violation: Apache-2.0 â†’ MIT (incompatible)
- âŒ No LICENSE file present

#### File-by-File Analysis:
| File | Similarity | Status |
|------|-----------|--------|
| src/core/algorithm.js | 100% | Exact copy |
| src/utils/helpers.js | 98% | Near-exact copy |
| README.md | 45% | Partially rewritten |

#### Recommended Actions:
1. Add attribution header to all copied files
2. Correct license to Apache-2.0 (or obtain permission)
3. Include original LICENSE file
4. Add NOTICE file with attribution
5. Update package.json metadata
```

---

## Remediation Strategies

### Automated Remediation Levels

```
Level 1: AUTOMATED (No human approval needed)
â”œâ”€â”€ Add missing LICENSE files (when license is declared)
â”œâ”€â”€ Add attribution comments to files
â”œâ”€â”€ Generate NOTICE files
â””â”€â”€ Update package.json metadata

Level 2: SEMI-AUTOMATED (Human approval required)
â”œâ”€â”€ License change recommendations
â”œâ”€â”€ THIRD_PARTY_NOTICES generation
â”œâ”€â”€ Automated PR creation
â””â”€â”€ Marketplace metadata updates

Level 3: MANUAL (Complex cases)
â”œâ”€â”€ License incompatibility resolution
â”œâ”€â”€ Negotiation with original authors
â”œâ”€â”€ Legal review required
â””â”€â”€ Marketplace policy enforcement
```

### Remediation Workflow

```python
class AttributionRemediator:
    def remediate(self, evidence_package):
        """
        Automated remediation based on evidence
        """
        remediation_plan = {
            'actions': [],
            'confidence': evidence_package.confidence_score,
            'requires_approval': False
        }

        # Generate attribution headers
        if evidence_package.classification == 'HIGH_CONFIDENCE_DERIVATIVE':
            for file in evidence_package.exact_matches:
                header = self.generate_attribution_header(
                    file=file,
                    original_author=evidence_package.suspected_source.author,
                    original_license=evidence_package.suspected_source.license,
                    source_url=evidence_package.suspected_source.repository
                )
                remediation_plan['actions'].append({
                    'type': 'ADD_HEADER',
                    'file': file,
                    'content': header
                })

        # License correction
        if evidence_package.license_analysis.compatibility == 'INCOMPATIBLE':
            remediation_plan['actions'].append({
                'type': 'LICENSE_CORRECTION',
                'current': evidence_package.derivative_resource.license,
                'required': evidence_package.suspected_source.license,
                'reason': evidence_package.license_analysis.violation_type
            })
            remediation_plan['requires_approval'] = True

        # Generate NOTICE file
        notice_content = self.generate_notice_file(evidence_package)
        remediation_plan['actions'].append({
            'type': 'ADD_NOTICE_FILE',
            'content': notice_content
        })

        # Create pull request
        if self.config.auto_pr_enabled:
            pr = self.create_attribution_pr(remediation_plan)
            remediation_plan['pr_url'] = pr.url

        return remediation_plan
```

### Attribution Header Templates

```python
# Template for different file types
ATTRIBUTION_HEADERS = {
    'python': '''
# Original source: {source_url}
# Original author: {author}
# Original license: {license}
# Modified by: {current_author}
#
# This file is derived from {original_project} and is used under the
# terms of the {license} license. See LICENSE file for full text.
''',

    'javascript': '''
/**
 * Original source: {source_url}
 * Original author: {author}
 * Original license: {license}
 * Modified by: {current_author}
 *
 * This file is derived from {original_project} and is used under the
 * terms of the {license} license. See LICENSE file for full text.
 */
''',

    'markdown': '''
<!--
Original source: {source_url}
Original author: {author}
Original license: {license}
Modified by: {current_author}

This document is derived from {original_project} and is used under the
terms of the {license} license. See LICENSE file for full text.
-->
'''
}
```

---

## Implementation Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ATTRIBUTION FORENSICS SYSTEM                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Sources   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Marketplace   â”‚â—„â”€â”€â”€â”
â”‚   APIs          â”‚    â”‚
â”‚ â€¢ Git repos     â”‚    â”‚
â”‚ â€¢ License DBs   â”‚    â”‚
â”‚ â€¢ Community     â”‚    â”‚
â”‚   lists         â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Crawler    â”‚              â”‚  Fingerprinter  â”‚
â”‚  Service    â”‚              â”‚  Service        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Catalog   â”‚              â”‚ â€¢ Content hash  â”‚
â”‚ â€¢ Metadata  â”‚              â”‚ â€¢ Semantic      â”‚
â”‚ â€¢ Updates   â”‚              â”‚   embeddings    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚ â€¢ License scan  â”‚
       â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Matcher       â”‚
              â”‚  Service       â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ â€¢ Similarity   â”‚
              â”‚   search       â”‚
              â”‚ â€¢ Temporal     â”‚
              â”‚   analysis     â”‚
              â”‚ â€¢ Network      â”‚
              â”‚   graph        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Verification  â”‚
              â”‚  Service       â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ â€¢ Evidence     â”‚
              â”‚   collection   â”‚
              â”‚ â€¢ Confidence   â”‚
              â”‚   scoring      â”‚
              â”‚ â€¢ Manual queue â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Remediation   â”‚
              â”‚  Service       â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ â€¢ Header gen   â”‚
              â”‚ â€¢ PR creation  â”‚
              â”‚ â€¢ Marketplace  â”‚
              â”‚   updates      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Reporting     â”‚
              â”‚  Dashboard     â”‚
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â”‚ â€¢ Evidence     â”‚
              â”‚   visualizationâ”‚
              â”‚ â€¢ Statistics   â”‚
              â”‚ â€¢ Alerts       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Backend Services:**
```yaml
crawler_service:
  language: Python 3.11
  framework: FastAPI
  libraries:
    - httpx (async HTTP)
    - beautifulsoup4 (scraping)
    - ratelimit (API throttling)

fingerprinter_service:
  language: Python 3.11
  libraries:
    - ssdeep (fuzzy hashing)
    - tree-sitter (AST parsing)
    - sentence-transformers (embeddings)
    - scikit-learn (similarity)

matcher_service:
  language: Python 3.11
  database: PostgreSQL + pgvector (vector search)
  cache: Redis
  libraries:
    - numpy (numerical)
    - faiss (similarity search)
    - networkx (graph analysis)

verification_service:
  language: Python 3.11
  framework: FastAPI
  libraries:
    - jinja2 (report templates)
    - markdown (report generation)

remediation_service:
  language: Python 3.11
  libraries:
    - gitpython (git operations)
    - github (GitHub API)
    - requests (marketplace APIs)

dashboard:
  framework: Next.js 14
  libraries:
    - recharts (visualization)
    - tanstack-table (data tables)
    - tailwindcss (styling)
```

**Infrastructure:**
```yaml
deployment:
  platform: Kubernetes
  services:
    - crawler: 3 replicas
    - fingerprinter: 5 replicas (CPU intensive)
    - matcher: 2 replicas
    - verification: 2 replicas
    - remediation: 2 replicas
    - dashboard: 2 replicas

storage:
  metadata: PostgreSQL 15 (with pgvector extension)
  cache: Redis 7
  files: S3-compatible object storage
  vectors: Dedicated vector DB (Qdrant or Milvus)

queues:
  message_broker: RabbitMQ or Kafka
  task_queue: Celery with Redis backend

monitoring:
  metrics: Prometheus + Grafana
  logging: ELK stack
  tracing: Jaeger
```

---

## Claude Code Plugin Design

### Plugin Structure

```
attribution-forensics-plugin/
â”œâ”€â”€ plugin.json                 # Plugin metadata
â”œâ”€â”€ README.md                   # User documentation
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ scan-marketplace.md     # Scan entire marketplace
â”‚   â”œâ”€â”€ analyze-resource.md     # Analyze single resource
â”‚   â”œâ”€â”€ verify-attribution.md   # Verify existing attribution
â”‚   â”œâ”€â”€ generate-attribution.md # Generate attribution files
â”‚   â””â”€â”€ create-pr.md           # Create remediation PR
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ attribution-detective.md    # Investigation specialist
â”‚   â”œâ”€â”€ license-compliance-expert.md # License law specialist
â”‚   â””â”€â”€ remediation-engineer.md     # Fix automation specialist
â”œâ”€â”€ mcps/
â”‚   â””â”€â”€ attribution-forensics.json  # MCP server config
â”œâ”€â”€ settings/
â”‚   â””â”€â”€ forensics-config.json   # Plugin settings
â””â”€â”€ hooks/
    â””â”€â”€ pre-publish-check.md    # Prevent publishing without attribution
```

### Command: /scan-marketplace

```markdown
# Scan Marketplace for Attribution Issues

Performs comprehensive attribution forensics across a marketplace.

## Usage

```bash
/scan-marketplace <marketplace> [options]
```

## Arguments

- `marketplace` - Target marketplace (npm, vscode, claude-code, github-actions)
- `--scope` - Scan scope (all, package-name, author)
- `--threshold` - Similarity threshold (default: 0.7)
- `--output` - Output format (json, csv, markdown)

## Examples

```bash
# Scan all Claude Code components
/scan-marketplace claude-code --scope all

# Scan specific package
/scan-marketplace npm --scope @myorg/package

# Scan with custom threshold
/scan-marketplace vscode --threshold 0.8
```

## Process

1. **Crawl**: Download marketplace catalog
2. **Fingerprint**: Hash all resources
3. **Match**: Find similar resources across sources
4. **Verify**: Collect evidence packages
5. **Report**: Generate attribution report

## Output

Generates:
- `attribution-report.md` - Human-readable report
- `evidence-packages/` - Detailed evidence for each match
- `remediation-plan.json` - Automated fix suggestions
```

### Agent: attribution-detective

```markdown
# Attribution Detective Agent

You are an Attribution Detective specializing in identifying derivative works
and attribution gaps in software marketplaces.

## Expertise

- Code similarity analysis and pattern recognition
- License compliance and compatibility
- Temporal analysis and git forensics
- Metadata investigation
- Evidence collection and documentation

## Methodology

When investigating potential attribution issues:

1. **Gather Context**
   - What resource are we investigating?
   - What marketplace is it from?
   - What are we comparing it against?

2. **Fingerprint Analysis**
   - Calculate content similarity scores
   - Compare AST structures
   - Analyze semantic embeddings
   - Check for exact matches

3. **Temporal Investigation**
   - When was source first published?
   - When was derivative published?
   - What is the git history?

4. **License Analysis**
   - What licenses are declared?
   - Are they compatible?
   - Is attribution present?
   - Are license files included?

5. **Evidence Collection**
   - Document all findings
   - Calculate confidence score
   - Generate evidence package
   - Recommend actions

## Tools Available

- Content similarity calculator
- License compatibility checker
- Git history analyzer
- Evidence package generator
- Report template engine

## Output Format

For each investigation, provide:

1. **Executive Summary**: One paragraph verdict
2. **Confidence Score**: 0-100% with justification
3. **Evidence**: Detailed findings
4. **Recommendation**: Specific remediation actions
5. **Priority**: Low/Medium/High/Critical

## Example Investigation

**Resource**: @example/utils v1.0.0
**Suspected Source**: lodash v4.17.21

**Findings**:
- Content similarity: 78%
- 12 functions match exactly
- Published 2 years after lodash
- License: MIT (same as lodash)
- Attribution: âŒ NOT PRESENT

**Verdict**: High-confidence derivative work requiring attribution

**Recommendation**: Add attribution headers, include NOTICE file

**Priority**: Medium (license compatible but attribution missing)
```

### MCP Server: attribution-forensics

```json
{
  "name": "attribution-forensics",
  "version": "1.0.0",
  "description": "Attribution forensics and remediation tools",
  "server": {
    "command": "npx",
    "args": ["-y", "@attribution-forensics/mcp-server"]
  },
  "tools": [
    {
      "name": "scan_resource",
      "description": "Scan a resource for attribution issues",
      "parameters": {
        "resource_url": "string",
        "marketplace": "string",
        "comparison_sources": "array"
      }
    },
    {
      "name": "calculate_similarity",
      "description": "Calculate similarity between two resources",
      "parameters": {
        "resource1_url": "string",
        "resource2_url": "string",
        "methods": "array"
      }
    },
    {
      "name": "verify_license_compliance",
      "description": "Verify license compliance for derivative work",
      "parameters": {
        "derivative_license": "string",
        "source_license": "string"
      }
    },
    {
      "name": "generate_attribution_header",
      "description": "Generate attribution header for file",
      "parameters": {
        "file_type": "string",
        "original_author": "string",
        "original_license": "string",
        "source_url": "string"
      }
    },
    {
      "name": "create_remediation_pr",
      "description": "Create PR with attribution fixes",
      "parameters": {
        "repository": "string",
        "evidence_package": "object"
      }
    }
  ]
}
```

---

## Scalability Considerations

### Handling Millions of Resources

**Challenge**: npm has 2.5M packages, how do we scan them all?

**Solution: Multi-stage Pipeline with Incremental Processing**

```python
class ScalableForensicsPipeline:
    """
    Process millions of resources efficiently
    """

    def __init__(self):
        self.stages = [
            QuickFilterStage(),      # Fast, low-accuracy filters
            DeepAnalysisStage(),      # Slower, high-accuracy analysis
            ManualReviewStage()       # Human verification
        ]

    def process_marketplace(self, marketplace):
        """
        Stage 1: Quick Filter (process ALL resources)
        - Fast metadata checks
        - 1000 resources/second
        - Filters out 95% of resources
        """
        quick_scan_results = []
        for batch in self.batch_iterator(marketplace.resources, size=1000):
            suspicious = self.stages[0].filter(batch)
            quick_scan_results.extend(suspicious)

        print(f"Stage 1: {len(quick_scan_results)} suspicious resources")

        """
        Stage 2: Deep Analysis (process 5% suspicious)
        - Content similarity
        - 10 resources/second
        - Identifies 80% as false positives
        """
        deep_analysis_results = []
        for resource in quick_scan_results:
            analysis = self.stages[1].analyze(resource)
            if analysis.confidence > 0.7:
                deep_analysis_results.append(analysis)

        print(f"Stage 2: {len(deep_analysis_results)} high-confidence matches")

        """
        Stage 3: Manual Review (process 1% high-confidence)
        - Human verification
        - Complex cases
        """
        for evidence in deep_analysis_results:
            self.stages[2].queue_for_review(evidence)
```

**Optimization Techniques:**

1. **Bloom Filters**: Quick membership testing
2. **Locality-Sensitive Hashing (LSH)**: Fast approximate matching
3. **Vector Indexing**: FAISS for similarity search
4. **Distributed Processing**: Spark/Dask for parallel analysis
5. **Caching**: Aggressive caching of fingerprints and results
6. **Incremental Updates**: Only scan new/changed resources

**Performance Targets:**

| Stage | Resources/Second | Coverage |
|-------|-----------------|----------|
| Quick Filter | 1,000 | 100% |
| Deep Analysis | 10 | 5% (suspicious) |
| Manual Review | 1 (human) | 1% (high-confidence) |

**Time Estimates:**

- npm (2.5M packages):
  - Stage 1: ~42 minutes
  - Stage 2: ~3.5 hours
  - Stage 3: Ongoing (queue)

- Total automated time: **~4 hours** for complete scan

### Continuous Monitoring

**Real-time Detection:**

```python
class ContinuousMonitor:
    """
    Monitor marketplaces in real-time
    """

    def monitor_marketplace_events(self, marketplace):
        """
        Subscribe to marketplace event feeds
        """
        for event in marketplace.event_stream():
            if event.type == 'PACKAGE_PUBLISHED':
                # Immediate forensics check
                evidence = self.quick_forensics(event.package)

                if evidence.confidence > 0.8:
                    # Alert maintainers
                    self.alert(evidence)

                    # Block publication (if enabled)
                    if self.config.block_suspicious_publishes:
                        marketplace.block_publish(event.package)
```

---

## Legal and Ethical Framework

### Ethical Guidelines

**Principles:**

1. **Presumption of Good Faith**: Assume accidental omission, not malice
2. **Proportional Response**: Match response to severity
3. **Education First**: Help maintainers fix, don't punish
4. **Transparency**: Make detection methods public
5. **Appeal Process**: Allow for false positive appeals

**False Positive Handling:**

```python
FALSE_POSITIVE_CATEGORIES = {
    'common_patterns': {
        'example': 'Boilerplate code (package.json templates)',
        'action': 'Whitelist pattern',
        'confidence_adjustment': -0.3
    },
    'standard_implementations': {
        'example': 'Standard algorithm implementations',
        'action': 'Lower threshold for well-known algorithms',
        'confidence_adjustment': -0.2
    },
    'trivial_similarities': {
        'example': 'Single-line utilities',
        'action': 'Require minimum code size',
        'confidence_adjustment': -0.4
    },
    'parallel_development': {
        'example': 'Multiple implementations of same spec',
        'action': 'Check for common spec reference',
        'confidence_adjustment': -0.3
    }
}
```

### Legal Considerations

**Important Disclaimers:**

âš ï¸ **This tool provides guidance, not legal advice**

- Detection != Proof of copyright infringement
- Similarity can have legitimate causes
- License interpretation requires legal expertise
- Consult lawyers for high-stakes cases

**Safe Harbor Provisions:**

For marketplace operators:

1. **DMCA Safe Harbor**: Respond promptly to takedown notices
2. **Good Faith Efforts**: Reasonable efforts to prevent violations
3. **Transparency**: Clear policies and appeals process
4. **Education**: Help users understand licensing

**Remediation Priorities:**

```
Priority 1: LEGAL VIOLATIONS (immediate action)
â”œâ”€â”€ Copyleft violation (GPL â†’ MIT)
â”œâ”€â”€ Patent clause violation
â”œâ”€â”€ Trademark infringement
â””â”€â”€ DMCA takedown notices

Priority 2: ATTRIBUTION GAPS (30-day notice)
â”œâ”€â”€ Missing attribution (compatible licenses)
â”œâ”€â”€ Missing NOTICE files
â”œâ”€â”€ Incomplete copyright notices
â””â”€â”€ Missing license files

Priority 3: BEST PRACTICES (advisory)
â”œâ”€â”€ Add CITATION.cff
â”œâ”€â”€ Improve attribution headers
â”œâ”€â”€ Document dependencies
â””â”€â”€ Update CHANGELOG
```

---

## Implementation Roadmap

### Phase 1: MVP (Months 1-3)

**Goal**: Basic detection and evidence collection

- [ ] Implement content fingerprinting
- [ ] Build similarity matcher
- [ ] Create evidence package format
- [ ] Develop manual review interface
- [ ] Test on small marketplaces (< 1,000 resources)

**Deliverable**: CLI tool that can scan a repository

### Phase 2: Automation (Months 4-6)

**Goal**: Automated remediation

- [ ] Attribution header generation
- [ ] Automated PR creation
- [ ] License compliance checker
- [ ] Remediation workflow engine
- [ ] Integration with GitHub/GitLab

**Deliverable**: Claude Code plugin with automation

### Phase 3: Scale (Months 7-9)

**Goal**: Handle large marketplaces

- [ ] Distributed processing infrastructure
- [ ] Vector database integration
- [ ] Incremental update system
- [ ] Performance optimization
- [ ] Continuous monitoring

**Deliverable**: Service that can scan npm in < 4 hours

### Phase 4: Platform (Months 10-12)

**Goal**: Multi-marketplace support

- [ ] Marketplace adapters (npm, VS Code, etc.)
- [ ] Web dashboard
- [ ] API for third-party integration
- [ ] Reporting and analytics
- [ ] Community features (appeals, discussions)

**Deliverable**: SaaS platform for attribution forensics

---

## Success Metrics

**Detection Accuracy:**
- **Precision**: >95% (few false positives)
- **Recall**: >85% (catch most issues)
- **F1 Score**: >90%

**Performance:**
- **Scan Speed**: 1,000 resources/second (stage 1)
- **Latency**: <5 minutes for single resource analysis
- **Scalability**: Handle 10M+ resource catalogs

**Remediation:**
- **Auto-Fix Rate**: >70% of issues (no human needed)
- **PR Acceptance**: >80% of attribution PRs merged
- **Time to Fix**: <7 days median

**Impact:**
- **Attribution Coverage**: Increase from ~30% to >90%
- **License Compliance**: Reduce violations by 80%
- **Community Trust**: Measurable increase in trust scores

---

## Conclusion

Attribution forensics at scale requires:

1. **Multi-layered Detection**: Fast filters + deep analysis
2. **Comprehensive Evidence**: Automated collection and documentation
3. **Intelligent Remediation**: Automate 70%+ of fixes
4. **Scalable Architecture**: Handle millions of resources
5. **Ethical Framework**: Balance enforcement with education

This methodology can be implemented as a **Claude Code Plugin** to make
attribution forensics accessible to all marketplace maintainers and
open source communities.

**Next Steps:**
1. Review this methodology
2. Prioritize features for MVP
3. Build proof-of-concept tool
4. Test on real marketplaces
5. Iterate based on feedback

---

**Document Version**: 1.0
**Last Updated**: November 5, 2025
**Contributors**: Attribution Forensics Working Group
**License**: CC-BY-4.0 (This methodology document)
